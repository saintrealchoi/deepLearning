{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "312c69fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "import json\n",
    "\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from PIL import Image\n",
    "\n",
    "from torchinfo import summary\n",
    "import torch.optim as optim\n",
    "from tqdm.notebook import tqdm\n",
    "from tensorboardX import SummaryWriter\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bcb3da63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6d4cd798",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training settings\n",
    "batch_size = 2\n",
    "lr = 3e-5\n",
    "gamma = 0.7\n",
    "seed = 42\n",
    "image_size = (3,256,256)\n",
    "batch_size = 2\n",
    "sequence_length = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61dc78bd",
   "metadata": {},
   "source": [
    "# DATASET\n",
    "\n",
    "video - frame(초당 1프레임 불러들이기) [100초일 경우 100프레임] - 프레임 20개를 1개의 sequence로 바꾸기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1a5d46fc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# import random\n",
    "# seed = 777\n",
    "# random.seed(seed)\n",
    "# example = torch.randn((16,3,224,224))\n",
    "# y = [random.randrange(0,2) for i in range(16)]\n",
    "# print(example.shape)\n",
    "# print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "76a2b147",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('data', exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4961476a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = 'data/train'\n",
    "test_dir = 'data/test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "903fbb99",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_list = glob.glob(os.path.join(train_dir,'*.jpg'))\n",
    "test_list = glob.glob(os.path.join(test_dir, '*.jpg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b95390c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Data: 25000\n",
      "Test Data: 12500\n"
     ]
    }
   ],
   "source": [
    "print(f\"Train Data: {len(train_list)}\")\n",
    "print(f\"Test Data: {len(test_list)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "39e0be8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [path.split('/')[-1].split('.')[0] for path in train_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff22a1da",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_idx = np.random.randint(1, len(train_list), size=9)\n",
    "fig, axes = plt.subplots(3, 3, figsize=(16, 12))\n",
    "\n",
    "for idx, ax in enumerate(axes.ravel()):\n",
    "    img = Image.open(train_list[idx])\n",
    "    ax.set_title(labels[idx])\n",
    "    ax.imshow(img)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0238b85",
   "metadata": {},
   "source": [
    "# split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bec50a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_list, valid_list = train_test_split(train_list, \n",
    "                                          test_size=0.2,\n",
    "                                          stratify=labels,\n",
    "                                          random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "13da856a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_list' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-c1c95c905090>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Train Data: {len(train_list)}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Validation Data: {len(valid_list)}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Test Data: {len(test_list)}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_list' is not defined"
     ]
    }
   ],
   "source": [
    "print(f\"Train Data: {len(train_list)}\")\n",
    "print(f\"Validation Data: {len(valid_list)}\")\n",
    "print(f\"Test Data: {len(test_list)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1237ff53",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d2f515f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f45f15a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MakeSequence(x,y,sequence_length):\n",
    "    x_seq = []\n",
    "    y_seq = []\n",
    "    for i in range(sequence_length):\n",
    "        x_seq.append(x[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9547ee38",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SeqDataset(Dataset):\n",
    "    def __init__(self,file_list,transform=None):\n",
    "        self.file_list = file_list\n",
    "        sefl.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        sefl.filelength = len(self.file_list)\n",
    "        return self.filelength\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        \n",
    "        x_seq = []\n",
    "        y_seq = []\n",
    "        for i in range(sequence_length):    \n",
    "            img_path = self.file_list[idx]\n",
    "            img = Image.open(img_path)\n",
    "            img_transformed = self.trasnform(img)\n",
    "            x_seq.append(img_transformed)\n",
    "            \n",
    "            label = open(label,'r')\n",
    "            label = label.readline()\n",
    "            label = 1 if label == \"1\" else 0\n",
    "            y_seq.append(label)\n",
    "            \n",
    "        return x_seq,y_seq\n",
    "    \n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "    \n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "42f0a532",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "    \n",
    "])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=None, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=32,\n",
    "                                          shuffle=True)\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=None, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=32,\n",
    "                                         shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "539fc5a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VGG19(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(VGG19, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            #3 224 128\n",
    "            nn.Conv2d(3, 64, 3, padding=1),nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(64, 64, 3, padding=1),nn.LeakyReLU(0.2),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            #64 112 64\n",
    "            nn.Conv2d(64, 128, 3, padding=1),nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(128, 128, 3, padding=1),nn.LeakyReLU(0.2),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            #128 56 32\n",
    "            nn.Conv2d(128, 256, 3, padding=1),nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(256, 256, 3, padding=1),nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(256, 256, 3, padding=1),nn.LeakyReLU(0.2),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            #256 28 16\n",
    "            nn.Conv2d(256, 512, 3, padding=1),nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(512, 512, 3, padding=1),nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(512, 512, 3, padding=1),nn.LeakyReLU(0.2),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            #512 14 8\n",
    "            #for memory\n",
    "#             nn.Conv2d(512, 512, 3, padding=1),nn.LeakyReLU(0.2),\n",
    "#             nn.Conv2d(512, 512, 3, padding=1),nn.LeakyReLU(0.2),\n",
    "#             nn.Conv2d(512, 512, 3, padding=1),nn.LeakyReLU(0.2),\n",
    "#             nn.MaxPool2d(2, 2)\n",
    "        )\n",
    "        #512 7 4\n",
    "        self.avg_pool = nn.AvgPool2d(14)\n",
    "        #512 1 1\n",
    "        self.classifier = nn.Linear(512, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        features = self.conv(x)\n",
    "        x = self.avg_pool(features)\n",
    "        x = torch.squeeze(x)\n",
    "        \n",
    "        #print(avg_pool.size())\n",
    "#         x = x.view(features.size(0), -1)\n",
    "        #print(flatten.size())\n",
    "#         x = self.classifier(x)\n",
    "        #x = self.softmax(x)\n",
    "    \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9999ec7f",
   "metadata": {},
   "source": [
    "batch, sequence, channel, w, h\n",
    "\n",
    "2,3,3,4,4\n",
    "\n",
    "x = torch.FloatTensor([[[[[1,1,1,1],[1,1,1,1],[1,1,1,1],[1,1,1,1]],\n",
    "                     [[1,1,1,1],[1,1,1,1],[1,1,1,1],[1,1,1,1]],\n",
    "                     [[1,1,1,1],[1,1,1,1],[1,1,1,1],[1,1,1,1]]],\n",
    "                     [[[2,2,2,2],[2,2,2,2],[2,2,2,2],[2,2,2,2]],\n",
    "                     [[2,2,2,2],[2,2,2,2],[2,2,2,2],[2,2,2,2]],\n",
    "                     [[2,2,2,2],[2,2,2,2],[2,2,2,2],[2,2,2,2]]],\n",
    "                      [[[3,3,3,3],[3,3,3,3],[3,3,3,3],[3,3,3,3]],\n",
    "                     [[3,3,3,3],[3,3,3,3],[3,3,3,3],[3,3,3,3]],\n",
    "                     [[3,3,3,3],[3,3,3,3],[3,3,3,3],[3,3,3,3]]]],\n",
    "                      [[[[4,4,4,4],[4,4,4,4],[4,4,4,4],[4,4,4,4]],\n",
    "                     [[4,4,4,4],[4,4,4,4],[4,4,4,4],[4,4,4,4]],\n",
    "                     [[4,4,4,4],[4,4,4,4],[4,4,4,4],[4,4,4,4]]],\n",
    "                     [[[5,5,5,5],[5,5,5,5],[5,5,5,5],[5,5,5,5]],\n",
    "                     [[5,5,5,5],[5,5,5,5],[5,5,5,5],[5,5,5,5]],\n",
    "                     [[5,5,5,5],[5,5,5,5],[5,5,5,5],[5,5,5,5]]],\n",
    "                      [[[6,6,6,6],[6,6,6,6],[6,6,6,6],[6,6,6,6]],\n",
    "                     [[6,6,6,6],[6,6,6,6],[6,6,6,6],[6,6,6,6]],\n",
    "                     [[6,6,6,6],[6,6,6,6],[6,6,6,6],[6,6,6,6]]]]]\n",
    "                     )\n",
    "                     \n",
    "#torch.Size([2, 3, 3, 4, 4])\n",
    "\n",
    "print(x.shape)\n",
    "\n",
    "x.view(6,3,4,4)\n",
    "\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5cf86b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "from torch.nn.utils.rnn import pack_padded_sequence\n",
    "import torch.nn.functional as F\n",
    "from torchvision.models import resnet18, resnet101\n",
    "\n",
    "\n",
    "class CNNLSTM(nn.Module):\n",
    "    def __init__(self, num_classes=2):\n",
    "        super(CNNLSTM, self).__init__()\n",
    "        self.resnet = resnet101(pretrained=True)\n",
    "        self.resnet.fc = nn.Sequential(nn.Linear(self.resnet.fc.in_features, 300))\n",
    "        self.lstm = nn.LSTM(input_size=300, hidden_size=256, num_layers=3)\n",
    "        self.fc1 = nn.Linear(256, 128)\n",
    "        self.fc2 = nn.Linear(128, num_classes)\n",
    "       \n",
    "    def forward(self, x_3d):\n",
    "        hidden = None\n",
    "        for t in range(x_3d.size(1)):\n",
    "            with torch.no_grad():\n",
    "                x = self.resnet(x_3d[:, t, :, :, :])  \n",
    "            out, hidden = self.lstm(x.unsqueeze(0), hidden)         \n",
    "\n",
    "        x = self.fc1(out[-1, :, :])\n",
    "        x = F.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89f88048",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNNLSTM().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7e02d5f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "\n",
    "class CNNLSTM(nn.Module):\n",
    "    def __init__(self,hidden_dim=128):\n",
    "        super().__init__()\n",
    "        \n",
    "        ## embedding with cnn\n",
    "        self.cnn = VGG19()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.lstm = nn.LSTM(512,\n",
    "                            hidden_dim,\n",
    "                            batch_first = True\n",
    "                           )\n",
    "        self.drop = nn.Dropout(p=0.5)\n",
    "        self.fc = nn.Linear(hidden_dim,1)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    def forward(self,x):\n",
    "        # num_layers*bidirectional, batch_size, n_hidden)\n",
    "        hidden = torch.zeros(1, 2, 128, requires_grad=True).to(device)\n",
    "        cell = torch.zeros(1, 2, 128, requires_grad=True).to(device)\n",
    "        \n",
    "        batchsize, time_steps,C,H,W = x.size()\n",
    "        c_in = x.view(batchsize * time_steps,C,H,W)\n",
    "        c_out = self.cnn(c_in)\n",
    "        r_in = c_out.view(batchsize, time_steps, -1)\n",
    "        r_out,(hn,cn) = self.lstm(r_in,(hidden,cell))\n",
    "        result = self.drop(r_out)\n",
    "        result = self.fc(result[-1])\n",
    "        result = torch.squeeze(result)\n",
    "        return torch.sigmoid(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d3810b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNNLSTM().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f4af2d71",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  ..\\c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "CNNLSTM                                  --                        --\n",
       "├─VGG19: 1-1                             [40, 512]                 --\n",
       "│    └─Sequential: 2-1                   [40, 512, 14, 14]         --\n",
       "│    │    └─Conv2d: 3-1                  [40, 64, 224, 224]        1,792\n",
       "│    │    └─LeakyReLU: 3-2               [40, 64, 224, 224]        --\n",
       "│    │    └─Conv2d: 3-3                  [40, 64, 224, 224]        36,928\n",
       "│    │    └─LeakyReLU: 3-4               [40, 64, 224, 224]        --\n",
       "│    │    └─MaxPool2d: 3-5               [40, 64, 112, 112]        --\n",
       "│    │    └─Conv2d: 3-6                  [40, 128, 112, 112]       73,856\n",
       "│    │    └─LeakyReLU: 3-7               [40, 128, 112, 112]       --\n",
       "│    │    └─Conv2d: 3-8                  [40, 128, 112, 112]       147,584\n",
       "│    │    └─LeakyReLU: 3-9               [40, 128, 112, 112]       --\n",
       "│    │    └─MaxPool2d: 3-10              [40, 128, 56, 56]         --\n",
       "│    │    └─Conv2d: 3-11                 [40, 256, 56, 56]         295,168\n",
       "│    │    └─LeakyReLU: 3-12              [40, 256, 56, 56]         --\n",
       "│    │    └─Conv2d: 3-13                 [40, 256, 56, 56]         590,080\n",
       "│    │    └─LeakyReLU: 3-14              [40, 256, 56, 56]         --\n",
       "│    │    └─Conv2d: 3-15                 [40, 256, 56, 56]         590,080\n",
       "│    │    └─LeakyReLU: 3-16              [40, 256, 56, 56]         --\n",
       "│    │    └─MaxPool2d: 3-17              [40, 256, 28, 28]         --\n",
       "│    │    └─Conv2d: 3-18                 [40, 512, 28, 28]         1,180,160\n",
       "│    │    └─LeakyReLU: 3-19              [40, 512, 28, 28]         --\n",
       "│    │    └─Conv2d: 3-20                 [40, 512, 28, 28]         2,359,808\n",
       "│    │    └─LeakyReLU: 3-21              [40, 512, 28, 28]         --\n",
       "│    │    └─Conv2d: 3-22                 [40, 512, 28, 28]         2,359,808\n",
       "│    │    └─LeakyReLU: 3-23              [40, 512, 28, 28]         --\n",
       "│    │    └─MaxPool2d: 3-24              [40, 512, 14, 14]         --\n",
       "│    └─AvgPool2d: 2-2                    [40, 512, 1, 1]           --\n",
       "├─LSTM: 1-2                              [2, 20, 128]              328,704\n",
       "├─Linear: 1-3                            [20, 2]                   258\n",
       "==========================================================================================\n",
       "Total params: 7,964,226\n",
       "Trainable params: 7,964,226\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (G): 558.92\n",
       "==========================================================================================\n",
       "Input size (MB): 24.08\n",
       "Forward/backward pass size (MB): 4238.91\n",
       "Params size (MB): 31.86\n",
       "Estimated Total Size (MB): 4294.85\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(model,(batch_size,sequence_length,3,224,224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "552770ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(),lr=0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4f37cb87",
   "metadata": {},
   "outputs": [],
   "source": [
    "writer= SummaryWriter('runs/cnn-lstm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7f5d25c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for epoch in range(10):\n",
    "#     epoch_loss = 0\n",
    "#     epoch_acc = 0\n",
    "    \n",
    "#     for data,label in tqdm(trainloader):\n",
    "#         data = data.to(device)\n",
    "#         label = label.to(device)\n",
    "        \n",
    "#         output = model(data)\n",
    "        \n",
    "#         loss = criterion(output,label)\n",
    "        \n",
    "#         optimizer.zero_grad()\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "        \n",
    "#         acc = (output.argmax(dim=1) == label).float().mean()\n",
    "#         epoch_loss += loss / len(trainloader)\n",
    "#         epoch_acc += acc /len(trainloader)\n",
    "        \n",
    "#     with torch.no_grad():\n",
    "#         epoch_val_accuracy = 0\n",
    "#         epoch_val_loss = 0\n",
    "#         for data, label in testloader:\n",
    "#             data = data.to(device)\n",
    "#             label = label.to(device)\n",
    "\n",
    "#             val_output = model(data)\n",
    "#             val_loss = criterion(val_output, label)\n",
    "\n",
    "#             acc = (val_output.argmax(dim=1) == label).float().mean()\n",
    "#             epoch_val_accuracy += acc / len(testloader)\n",
    "#             epoch_val_loss += val_loss / len(testloader)\n",
    "#         writer.add_scalar('validation_loss',epoch_val_loss,epoch)\n",
    "\n",
    "#     writer.add_scalar('training_loss',epoch_loss,epoch)\n",
    "\n",
    "\n",
    "#     print(\n",
    "#         f\"Epoch : {epoch+1} - loss : {epoch_loss:.4f} - acc: {epoch_acc:.4f} - val_loss : {epoch_val_loss:.4f} - val_acc: {epoch_val_accuracy:.4f}\\n\"\n",
    "#     )\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ccced62",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
